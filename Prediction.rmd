---
title: "Exercise Prediction"
output: html_document
---
###By Jayateerth Katti
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Introduction

The document describes apporoach to buil a predictive model for the Weight Lifting Exercises Dataset.The goal is to fit a predictive model to the provided data in order to predict the kind of eightlifting that was performed. It turns out that we can fit calssification tree and random forest model which predict on sample data.

##Data Processing

##Import the Data
First we will load all the libraries required
```{r }
library(caret)
library(rattle)
library(rpart.plot)
library(randomForest)

#Load the the data
training <- read.csv("./Data/pml-training.csv", na.strings = c("NA", ""))
testing<-read.csv("./Data/pml-testing.csv",na.strings = c("NA",""))

dim(training)
dim(testing)
```
About data :-Training dataset has 19622 rows and 160 variables.Testing dataset has 20 rows and 160 variables.Here we will try to predict the outcome of 'calsse' variable in the training set.

```{r  }
names(training)

```
###Data Cleaning
The training dataset has many missing values.We will delete those variables Also, forst 7 variables do not seem to have any impact on prediction. So we will delete them.We do the same for testing dataset as well.

```{r }
training<-training[,colSums(is.na(training))==0]
testing<-testing[,colSums(is.na(testing))==0]

#Remove first 7 variables
trainigData<-training[,-c(1:7)]
testingData<-testing[,-c(1:7)]

dim(trainigData)
dim(testingData)
```
So,now we have 19622 observations and 53 variables in training dataset.Testing dataset has 20 observations and 53 variables.

###Data splitting for Validation
Split cleaned data to 70-30% for training and validation
```{r }
set.seed(8000)
inTrain<-createDataPartition(trainigData$classe,p=0.7,list=FALSE)
train<-trainigData[inTrain,]
valid<-trainigData[-inTrain,]
```
##Prediction 
We use Classification trees and Random forests to predict the outcome.

###Classification Trees
We will not be transforming the data as we are using classification algortihms.

```{r }
fit1<-rpart(classe ~ .,data=train,method = "class")

```
Plot the graph

```{r }
fancyRpartPlot(fit1)   

```   

   
###Predict the outcome using validation dataset

```{r }
predict1<-predict(fit1,valid,type = "class")

#Confusion matrix for accuracy
(conf_rpart<-confusionMatrix(predict1,valid$classe))

#Display only Accuracy
(accuracy_rpart<-conf_rpart$overall[1])

```
From the consuiosn matrix, it is found that accuracy rate is 0.73.   

###Random Forests

```{r }
fit2<-randomForest(classe ~ .,data=train,method="class")
predict2<-predict(fit2,valid,type = "class")

#Confusion matrix for accuracy
(conf_rfor<-confusionMatrix(predict2,valid$classe))

#Display only Accuracy
(accuracy_rpart<-conf_rfor$overall[1])

#plot fit
plot(fit2,main = "Fit using Random Forests")

```

From the consuiosn matrix, it is found that accuracy rate is ***0.99.This model is more accurate.***
